{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8172a77-cf83-4a0b-9d4b-aafff9409783",
   "metadata": {},
   "source": [
    "<table align=\"left\" width=100%>\n",
    "    <tr>\n",
    "        <td width=\"10%\">\n",
    "            <img src=\"../images/RA_Logo.png\">\n",
    "        </td>\n",
    "        <td>\n",
    "            <div align=\"center\">\n",
    "                <font color=\"#21618C\" size=8px>\n",
    "                  <b> 9. Semantic Analysis </b>\n",
    "                </font>\n",
    "            </div>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6c8ff5-571f-4171-8894-426151570cec",
   "metadata": {},
   "source": [
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a href=\"https://colab.research.google.com/github/vidyadharbendre/learn_nlp_using_examples/blob/main/notebooks/09_Semantic_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://kaggle.com/kernels/welcome?src=https://github.com/vidyadharbendre/learn_nlp_using_examples/blob/main/notebooks/09_Semantic_Analysis.ipynb\"><img src=\"https://kaggle.com/static/images/open-in-kaggle.svg\" /></a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f852baf-702c-4df4-9c77-985452ece7fa",
   "metadata": {},
   "source": [
    "## What is Semantic Analysis?\n",
    "Semantic Analysis is the process of understanding the meaning and interpretation of words, phrases, and sentences in context. It involves analyzing the relationships and meanings of words to determine the intended message of the text.\n",
    "\n",
    "## Why Semantic Analysis?\n",
    "Semantic Analysis is essential for:\n",
    "\n",
    "Improving the accuracy of NLP tasks like sentiment analysis, machine translation, and information retrieval.\n",
    "Enhancing the understanding of context and meaning in text.\n",
    "Supporting more sophisticated text analysis and interpretation.\n",
    "\n",
    "## How to Achieve Semantic Analysis Programmatically?\n",
    "Using SpaCy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16b47d82-5492-4ee1-b3c9-a5539312e146",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name util",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mspacy\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Print the version of SpaCy installed\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(spacy\u001b[38;5;241m.\u001b[39m__version__)\n",
      "File \u001b[0;32m~/miniforge3/envs/nlp_env/lib/python3.9/site-packages/spacy/__init__.py:14\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mthinc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m prefer_gpu, require_gpu, require_cpu  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mthinc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Config\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pipeline  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcli\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minfo\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m info  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mglossary\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m explain  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/nlp_env/lib/python3.9/site-packages/spacy/pipeline/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mattributeruler\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AttributeRuler\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdep_parser\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DependencyParser\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01medit_tree_lemmatizer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EditTreeLemmatizer\n",
      "File \u001b[0;32m~/miniforge3/envs/nlp_env/lib/python3.9/site-packages/spacy/pipeline/attributeruler.py:6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msrsly\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpathlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpipe\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Pipe\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01merrors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Errors\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtraining\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Example\n",
      "File \u001b[0;32m~/miniforge3/envs/nlp_env/lib/python3.9/site-packages/spacy/pipeline/pipe.pyx:1\u001b[0m, in \u001b[0;36minit spacy.pipeline.pipe\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniforge3/envs/nlp_env/lib/python3.9/site-packages/spacy/vocab.pyx:1\u001b[0m, in \u001b[0;36minit spacy.vocab\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniforge3/envs/nlp_env/lib/python3.9/site-packages/spacy/tokens/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdoc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Doc\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtoken\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Token\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspan\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Span\n",
      "File \u001b[0;32m~/miniforge3/envs/nlp_env/lib/python3.9/site-packages/spacy/tokens/doc.pyx:34\u001b[0m, in \u001b[0;36minit spacy.tokens.doc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name util"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Print the version of SpaCy installed\n",
    "print(spacy.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98c668f7-64a5-4ebb-a3f7-a71cc7444d58",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name util",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mspacy\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Print the version of SpaCy installed\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(spacy\u001b[38;5;241m.\u001b[39m__version__)\n",
      "File \u001b[0;32m~/miniforge3/envs/nlp_env/lib/python3.9/site-packages/spacy/__init__.py:14\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mthinc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m prefer_gpu, require_gpu, require_cpu  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mthinc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Config\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pipeline  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcli\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minfo\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m info  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mglossary\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m explain  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/nlp_env/lib/python3.9/site-packages/spacy/pipeline/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mattributeruler\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AttributeRuler\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdep_parser\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DependencyParser\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01medit_tree_lemmatizer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EditTreeLemmatizer\n",
      "File \u001b[0;32m~/miniforge3/envs/nlp_env/lib/python3.9/site-packages/spacy/pipeline/attributeruler.py:6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msrsly\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpathlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpipe\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Pipe\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01merrors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Errors\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtraining\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Example\n",
      "File \u001b[0;32m~/miniforge3/envs/nlp_env/lib/python3.9/site-packages/spacy/pipeline/pipe.pyx:1\u001b[0m, in \u001b[0;36minit spacy.pipeline.pipe\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniforge3/envs/nlp_env/lib/python3.9/site-packages/spacy/vocab.pyx:1\u001b[0m, in \u001b[0;36minit spacy.vocab\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniforge3/envs/nlp_env/lib/python3.9/site-packages/spacy/tokens/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdoc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Doc\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtoken\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Token\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspan\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Span\n",
      "File \u001b[0;32m~/miniforge3/envs/nlp_env/lib/python3.9/site-packages/spacy/tokens/doc.pyx:34\u001b[0m, in \u001b[0;36minit spacy.tokens.doc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name util"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Print the version of SpaCy installed\n",
    "print(spacy.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce1d2f36-6b7d-4e67-972f-2466b2e76b49",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name util",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mspacy\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Load SpaCy's English language model\u001b[39;00m\n\u001b[1;32m      4\u001b[0m nlp \u001b[38;5;241m=\u001b[39m spacy\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124men_core_web_sm\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/envs/nlp_env/lib/python3.9/site-packages/spacy/__init__.py:14\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mthinc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m prefer_gpu, require_gpu, require_cpu  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mthinc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Config\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pipeline  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcli\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minfo\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m info  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mglossary\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m explain  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/nlp_env/lib/python3.9/site-packages/spacy/pipeline/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mattributeruler\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AttributeRuler\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdep_parser\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DependencyParser\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01medit_tree_lemmatizer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EditTreeLemmatizer\n",
      "File \u001b[0;32m~/miniforge3/envs/nlp_env/lib/python3.9/site-packages/spacy/pipeline/attributeruler.py:6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msrsly\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpathlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpipe\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Pipe\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01merrors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Errors\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtraining\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Example\n",
      "File \u001b[0;32m~/miniforge3/envs/nlp_env/lib/python3.9/site-packages/spacy/pipeline/pipe.pyx:1\u001b[0m, in \u001b[0;36minit spacy.pipeline.pipe\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniforge3/envs/nlp_env/lib/python3.9/site-packages/spacy/vocab.pyx:1\u001b[0m, in \u001b[0;36minit spacy.vocab\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniforge3/envs/nlp_env/lib/python3.9/site-packages/spacy/tokens/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdoc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Doc\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtoken\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Token\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspan\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Span\n",
      "File \u001b[0;32m~/miniforge3/envs/nlp_env/lib/python3.9/site-packages/spacy/tokens/doc.pyx:34\u001b[0m, in \u001b[0;36minit spacy.tokens.doc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name util"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Load SpaCy's English language model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Example text\n",
    "text = \"Apple is looking at buying a U.K. startup for $1 billion.\"\n",
    "\n",
    "# Process the text with SpaCy\n",
    "doc = nlp(text)\n",
    "\n",
    "# Semantic analysis using SpaCy\n",
    "semantic_analysis_spacy = [(token.text, token.vector) for token in doc]\n",
    "\n",
    "# Display token text and vector\n",
    "for token_text, token_vector in semantic_analysis_spacy:\n",
    "    print(f\"Token: {token_text}, Vector: {token_vector[:5]}\")  # Displaying first 5 dimensions of the vector for brevity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59eb6ade-cf08-49ce-8eac-cb8c5a7db33a",
   "metadata": {},
   "source": [
    "Using NLTK:\n",
    "NLTK does not have built-in capabilities for vector-based semantic analysis directly. However, you can use word2vec or GloVe pre-trained word vectors from external libraries like gensim to perform semantic analysis. Here's an example using gensim:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e42ca89-4a6b-4e66-ba5a-1b260bc7f86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!conda list scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e7cf54-91e9-416e-a719-4f46054b8c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!conda install -c conda-forge gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a29cc74-b77e-4732-a452-5a150090571b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!conda install --force-reinstall scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942c302c-afed-46f7-94ea-d79177959bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "print(scipy.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ac5a3b-6ce9-437f-9d98-3e3d6c85f4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!conda update -n nlp_env scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d12f42-8b13-4a3b-a957-c5b8a1b30480",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.linalg.triu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd524ba-e0d2-4761-8f92-bc5b748c629d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.linalg import triu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156edc16-d409-46a9-96df-8aa3ddd7d475",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.linalg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e19554-153e-499e-a51f-d5da8a9827dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# Ensure necessary resources are downloaded\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Sample text\n",
    "text = \"Hello, how are you?\"\n",
    "\n",
    "# Tokenize text\n",
    "tokens = word_tokenize(text)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1552b0ea-b8f0-4e3d-a455-dd3847b9042b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# Ensure necessary resources are downloaded\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Load pre-trained Word2Vec model (for example purposes, using a small pre-trained model)\n",
    "# You can download a larger model from gensim-data or use your own pre-trained model\n",
    "word2vec_model = KeyedVectors.load_word2vec_format('path/to/GoogleNews-vectors-negative300.bin', binary=True)\n",
    "\n",
    "# Example text\n",
    "text = \"Apple is looking at buying a U.K. startup for $1 billion.\"\n",
    "\n",
    "# Tokenize the text\n",
    "words = word_tokenize(text)\n",
    "\n",
    "# Semantic analysis using Word2Vec\n",
    "semantic_analysis_word2vec = [(word, word2vec_model[word]) for word in words if word in word2vec_model]\n",
    "\n",
    "# Display token text and vector\n",
    "for word, vector in semantic_analysis_word2vec:\n",
    "    print(f\"Word: {word}, Vector: {vector[:5]}\")  # Displaying first 5 dimensions of the vector for brevity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccd1874-a2ec-47a7-b63a-10ad5985d401",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e24af3a-5e17-4843-ab4b-8dfee0d59683",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip uninstall scipy\n",
    "#!pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab10613-cf28-4993-a6ac-744a1ddad2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f203fc86-0add-412a-9d71-40cdfc3d7112",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a394e204-6565-48e4-ad2e-ead4e459a5ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b19740c-9d67-4a1e-a6f0-794ad2b3d95f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
