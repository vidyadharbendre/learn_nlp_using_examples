{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table align=\"left\" width=100%>\n",
    "    <tr>\n",
    "        <td width=\"10%\">\n",
    "            <img src=\"../images/RA_Logo.png\">\n",
    "        </td>\n",
    "        <td>\n",
    "            <div align=\"center\">\n",
    "                <font color=\"#21618C\" size=8px>\n",
    "                  <b> NLP Basics </b>\n",
    "                </font>\n",
    "            </div>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a href=\"https://colab.research.google.com/github/vidyadharbendre/learn_nlp_using_examples/blob/main/notebooks/NLP_basics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://kaggle.com/kernels/welcome?src=https://github.com/vidyadharbendre/learn_nlp_using_examples/blob/main/notebooks/NLP_basics.ipynb\"><img src=\"https://kaggle.com/static/images/open-in-kaggle.svg\" /></a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is a Corpus?\n",
    "\n",
    "## 1. Definition:\n",
    "\n",
    "A corpus is a collection of written texts or transcribed speech that is used for linguistic analysis and language processing tasks. It is often annotated with additional linguistic information such as part-of-speech tags, syntactic structures, and semantic annotations.\n",
    "\n",
    "## 2. Types of Corpora:\n",
    "\n",
    "a) General Corpus: Contains a wide variety of texts from different genres and domains (e.g., British National Corpus).\n",
    "b) Specialized Corpus: Focuses on a specific domain or genre (e.g., medical texts, legal documents).\n",
    "c) Monolingual Corpus: Contains texts in a single language.\n",
    "d) Multilingual Corpus: Contains texts in multiple languages, often used for translation and comparative studies.\n",
    "e) Parallel Corpus: A type of multilingual corpus where texts are aligned sentence by sentence across different languages, useful for translation studies.\n",
    "\n",
    "\n",
    "# Importance of Corpora in NLP\n",
    "\n",
    "## 1. Training Data:\n",
    "\n",
    "Corpora serve as the primary source of training data for various NLP models, such as language models, part-of-speech taggers, named entity recognition systems, and machine translation systems.\n",
    "\n",
    "## 2. Linguistic Research:\n",
    "\n",
    "Linguists use corpora to study language use, frequency of word usage, collocations, syntactic structures, and language change over time.\n",
    "\n",
    "## 3. Evaluation:\n",
    "\n",
    "NLP models are evaluated against benchmark corpora to assess their performance and accuracy. Standardized corpora like the Penn Treebank or the Reuters corpus provide a common ground for comparing different models and techniques.\n",
    "\n",
    "## 4. Text Analysis:\n",
    "\n",
    "Researchers and analysts use corpora for various text analysis tasks, such as sentiment analysis, topic modeling, and information extraction.\n",
    "\n",
    "# Example of a Well-Known Corpus: Reuters Corpus\n",
    "The Reuters Corpus, which youâ€™ve already seen in action, is a classic example of a specialized corpus used extensively in NLP:\n",
    "\n",
    "## Content: \n",
    "It contains 10,788 news documents covering various topics, with a significant focus on business and financial news.\n",
    "## Usage: \n",
    "It is widely used for text classification, clustering, and information retrieval tasks.\n",
    "## Access: \n",
    "In Python, the NLTK library provides easy access to the Reuters Corpus, allowing users to download and work with the data seamlessly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/vidyadharbendre/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove stop words\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords # Import stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenize\n",
    "\n",
    "from nltk import word_tokenize # Tokenize the file, which is similar to getting words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Content\n",
    "\n",
    "1. [Basic Text Reading](#Basic-Text-Reading)\n",
    "2. [Pre Processing](#Pre-Processing)\n",
    "3. [PoS Tagging](#PoS-Tagging)\n",
    "4. [Context](#Context)\n",
    "5. [Frequency](#Frequency)\n",
    "6. [Stemming Lemmatization](#Stemming-Lemmatization)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Text Reading\n",
    "<a id=\"Basic-Text-Reading\"></a>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The Reuters Corpus includes 10,788 news documents and over 1.3 million words. This makes it a substantial resource for training and testing NLP models.\n",
    "The variety of topics, particularly the focus on business and finance, provides a rich source of data for understanding language use in different contexts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package reuters to\n",
      "[nltk_data]     /Users/vidyadharbendre/nltk_data...\n",
      "[nltk_data]   Package reuters is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import reuters\n",
    "\n",
    "# Example usage\n",
    "nltk.download('reuters')\n",
    "#print(reuters.fileids())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 995,
     "status": "ok",
     "timestamp": 1581770247614,
     "user": {
      "displayName": "Sarbind Gupta",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCX_PdUc-oYjLw3bTTsusGGiLA4h-CJUT94gBbkRw=s64",
      "userId": "14604457747665098998"
     },
     "user_tz": -330
    },
    "id": "Etxq9RWbxWDZ",
    "outputId": "0ecadc59-a883-474d-8ca5-a163533f59c8"
   },
   "outputs": [],
   "source": [
    "#reuters.categories() # List news categories in the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1071,
     "status": "ok",
     "timestamp": 1581770261619,
     "user": {
      "displayName": "Sarbind Gupta",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCX_PdUc-oYjLw3bTTsusGGiLA4h-CJUT94gBbkRw=s64",
      "userId": "14604457747665098998"
     },
     "user_tz": -330
    },
    "id": "THA37ZJYxWDd",
    "outputId": "7dca697a-2ac3-47a1-f867-951171234a52"
   },
   "outputs": [],
   "source": [
    "#reuters.fileids(['wheat','rice']) # List file ids with either wheat or rice categories\n",
    "# Some file ids may overlap as news covers multiple categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1842,
     "status": "ok",
     "timestamp": 1581770311010,
     "user": {
      "displayName": "Sarbind Gupta",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCX_PdUc-oYjLw3bTTsusGGiLA4h-CJUT94gBbkRw=s64",
      "userId": "14604457747665098998"
     },
     "user_tz": -330
    },
    "id": "hU8fJauJxWDh",
    "outputId": "1b26abc1-2b27-4475-d7aa-34d7045a0651"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/vidyadharbendre/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Let us see how many chars, words and sentences are in each file\n",
    "nltk.download('punkt')\n",
    "for fileid in reuters.fileids(['wheat','rice']):\n",
    "    num_chars = len(reuters.raw(fileid))\n",
    "    num_words = len(reuters.words(fileid))\n",
    "    num_sents = len(reuters.sents(fileid))\n",
    "    num_vocab = len(set(w.lower() for w in reuters.words(fileid)))\n",
    "#    print(fileid, \" : \",num_chars, num_words, num_sents, num_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1226,
     "status": "ok",
     "timestamp": 1581770367032,
     "user": {
      "displayName": "Sarbind Gupta",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCX_PdUc-oYjLw3bTTsusGGiLA4h-CJUT94gBbkRw=s64",
      "userId": "14604457747665098998"
     },
     "user_tz": -330
    },
    "id": "gNImGLnwxWDl",
    "outputId": "54b692be-f67d-4fe2-9dfd-0eba991cc33a"
   },
   "outputs": [],
   "source": [
    "# Select one file for futher processing\n",
    "\n",
    "fileid = 'test/15618'\n",
    "\n",
    "#reuters.raw(fileid) # See what is in the selected file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1002,
     "status": "ok",
     "timestamp": 1581770396128,
     "user": {
      "displayName": "Sarbind Gupta",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCX_PdUc-oYjLw3bTTsusGGiLA4h-CJUT94gBbkRw=s64",
      "userId": "14604457747665098998"
     },
     "user_tz": -330
    },
    "id": "TlImJQZexWDo",
    "outputId": "b0b633c0-0584-48fb-956a-85343907547e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FRENCH', 'FREE', 'MARKET', 'CEREAL', 'EXPORT', ...]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reuters.words(fileid) # See individual words in the selected file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 991,
     "status": "ok",
     "timestamp": 1581770420555,
     "user": {
      "displayName": "Sarbind Gupta",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCX_PdUc-oYjLw3bTTsusGGiLA4h-CJUT94gBbkRw=s64",
      "userId": "14604457747665098998"
     },
     "user_tz": -330
    },
    "id": "CuTURxcdxWDr",
    "outputId": "cdf5b001-0edb-4ac2-bf37-2e6b000cb7dd"
   },
   "outputs": [],
   "source": [
    "# See sentences in the file. Notice the bracket within bracket for each sentence\n",
    "\n",
    "#reuters.sents(fileid) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre Processing\n",
    "<a id=\"Pre-Processing\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table align=\"left\">\n",
    "    <tr>\n",
    "        <td width=\"6%\">\n",
    "            <img src=\"../images/RA_Logo.png\">\n",
    "        </td>\n",
    "        <td>\n",
    "            <div align=\"left\", style=\"font-size:120%\">\n",
    "                <font color=\"#21618C\">\n",
    "                    <b>lower case, tokenization, removing stop words, finding words</b>\n",
    "                </font>\n",
    "            </div>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lower case, tokenization, removing stop words, finding words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1283,
     "status": "ok",
     "timestamp": 1581770476387,
     "user": {
      "displayName": "Sarbind Gupta",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCX_PdUc-oYjLw3bTTsusGGiLA4h-CJUT94gBbkRw=s64",
      "userId": "14604457747665098998"
     },
     "user_tz": -330
    },
    "id": "tdCnQOo-xWDv",
    "outputId": "cb52bbf8-f5be-41ad-bcfc-443ff374896e"
   },
   "outputs": [],
   "source": [
    "# See all the words in the file, lexicographically sorted\n",
    "\n",
    "#set(w.lower() for w in reuters.words(fileid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1016,
     "status": "ok",
     "timestamp": 1581770526724,
     "user": {
      "displayName": "Sarbind Gupta",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCX_PdUc-oYjLw3bTTsusGGiLA4h-CJUT94gBbkRw=s64",
      "userId": "14604457747665098998"
     },
     "user_tz": -330
    },
    "id": "fujdCEOZxWDz",
    "outputId": "e2e5b670-89fe-4515-8de0-78e2379774f0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/vidyadharbendre/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Remove stop words\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords # Import stop words\n",
    "#wordList = [w for w in reuters.words(fileid) if w.lower() not in stopwords.words('english')]\n",
    "#wordList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 988,
     "status": "ok",
     "timestamp": 1581770578748,
     "user": {
      "displayName": "Sarbind Gupta",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCX_PdUc-oYjLw3bTTsusGGiLA4h-CJUT94gBbkRw=s64",
      "userId": "14604457747665098998"
     },
     "user_tz": -330
    },
    "id": "u6AfvyOCxWD1",
    "outputId": "bb158a3c-8afa-49a0-fd8e-aab288eea6ff"
   },
   "outputs": [],
   "source": [
    "#Tokenize\n",
    "\n",
    "from nltk import word_tokenize # Tokenize the file, which is similar to getting words\n",
    "#tokens = word_tokenize(reuters.raw(fileid))\n",
    "#wordList = reuters.words(fileid)\n",
    "\n",
    "#tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1016,
     "status": "ok",
     "timestamp": 1581770609932,
     "user": {
      "displayName": "Sarbind Gupta",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCX_PdUc-oYjLw3bTTsusGGiLA4h-CJUT94gBbkRw=s64",
      "userId": "14604457747665098998"
     },
     "user_tz": -330
    },
    "id": "JXQs3vf5xWD4",
    "outputId": "6aa89460-bb4e-49d2-8023-2c573dca7f26"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'wordList' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Check out the difference between tokens and words. Tokenization is more intelligence segmentation\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mwordList\u001b[49m[\u001b[38;5;241m12\u001b[39m:\u001b[38;5;241m20\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'wordList' is not defined"
     ]
    }
   ],
   "source": [
    "# Check out the difference between tokens and words. Tokenization is more intelligence segmentation\n",
    "\n",
    "wordList[12:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1001,
     "status": "ok",
     "timestamp": 1581770637540,
     "user": {
      "displayName": "Sarbind Gupta",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCX_PdUc-oYjLw3bTTsusGGiLA4h-CJUT94gBbkRw=s64",
      "userId": "14604457747665098998"
     },
     "user_tz": -330
    },
    "id": "Ub0mI8epxWD6",
    "outputId": "2f2bfe46-d485-419d-e6bf-69f5cf0d720b"
   },
   "outputs": [],
   "source": [
    "# Find position of a word\n",
    "\n",
    "#reuters.raw(fileid).find('MARKET')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The', 'earth', 'is', 'an', 'awesome', 'place', 'live']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "sample_text = \"The earth is an awesome place live\"\n",
    "\n",
    "# Now you can use word_tokenize\n",
    "t = word_tokenize(sample_text)\n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QDTdUj-DxWD9"
   },
   "source": [
    "## PoS Tagging\n",
    "<a id=\"PoS-Tagging\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table align=\"left\">\n",
    "    <tr>\n",
    "        <td width=\"6%\">\n",
    "            <img src=\"../images/RA_Logo.png\">\n",
    "        </td>\n",
    "        <td>\n",
    "            <div align=\"left\", style=\"font-size:120%\">\n",
    "                <font color=\"#21618C\">\n",
    "                    <b>Synonyms, PoS Tagging, Parsing: Chunking, Chinking, Syntax Trees</b>\n",
    "                </font>\n",
    "            </div>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The diverse vocabulary in the Reuters Corpus helps in developing robust part-of-speech tagging models that can handle various contexts in business news."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1010,
     "status": "ok",
     "timestamp": 1581770736550,
     "user": {
      "displayName": "Sarbind Gupta",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCX_PdUc-oYjLw3bTTsusGGiLA4h-CJUT94gBbkRw=s64",
      "userId": "14604457747665098998"
     },
     "user_tz": -330
    },
    "id": "wL3ybta5xWD9",
    "outputId": "f6faee8c-784e-45bb-a2ea-ccac447a4f0b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/vidyadharbendre/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/vidyadharbendre/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Synset('trade.n.01'),\n",
       " Synset('trade.n.02'),\n",
       " Synset('trade.n.03'),\n",
       " Synset('deal.n.01'),\n",
       " Synset('craft.n.03'),\n",
       " Synset('trade_wind.n.01'),\n",
       " Synset('barter.n.01'),\n",
       " Synset('trade.v.01'),\n",
       " Synset('trade.v.02'),\n",
       " Synset('trade.v.03'),\n",
       " Synset('trade.v.04'),\n",
       " Synset('deal.v.06')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "# Check out some synonyms\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import wordnet as wn # See the list of synonyms\n",
    "wn.synsets('trade')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1254,
     "status": "ok",
     "timestamp": 1581770814743,
     "user": {
      "displayName": "Sarbind Gupta",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCX_PdUc-oYjLw3bTTsusGGiLA4h-CJUT94gBbkRw=s64",
      "userId": "14604457747665098998"
     },
     "user_tz": -330
    },
    "id": "OLTWy4hbxWEC",
    "outputId": "a2f17fb8-5429-4a1e-cec5-103d4e2b7148"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['trade', 'trade_in']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synset('trade.v.02').lemma_names() # Read one particular synonym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1792,
     "status": "ok",
     "timestamp": 1581770874970,
     "user": {
      "displayName": "Sarbind Gupta",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCX_PdUc-oYjLw3bTTsusGGiLA4h-CJUT94gBbkRw=s64",
      "userId": "14604457747665098998"
     },
     "user_tz": -330
    },
    "id": "EIrd5zFwxWEF",
    "outputId": "4a6fbfef-0d75-4a4f-a42a-32ae7ead7308"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wheat corn barley grain the march tonnes mln feedgrains up april farm\n",
      "sorghum soybeans june pct agriculture may grains cotton\n"
     ]
    }
   ],
   "source": [
    "# Find text with similar context\n",
    "\n",
    "text = nltk.Text(word.lower() for file_id in reuters.fileids(['wheat','rice']) for word in reuters.words(file_id))\n",
    "text.similar('rice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 987,
     "status": "ok",
     "timestamp": 1581770941957,
     "user": {
      "displayName": "Sarbind Gupta",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCX_PdUc-oYjLw3bTTsusGGiLA4h-CJUT94gBbkRw=s64",
      "userId": "14604457747665098998"
     },
     "user_tz": -330
    },
    "id": "MEn5GXINxWEH",
    "outputId": "894f318d-983f-442d-baef-6c3a63f328e2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/vidyadharbendre/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See PoS of tokens (for some corpora, POS are already tagged in this corpus)\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "#nltk.pos_tag(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1045,
     "status": "ok",
     "timestamp": 1581771265025,
     "user": {
      "displayName": "Sarbind Gupta",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCX_PdUc-oYjLw3bTTsusGGiLA4h-CJUT94gBbkRw=s64",
      "userId": "14604457747665098998"
     },
     "user_tz": -330
    },
    "id": "s3U7kHeCxWEJ",
    "outputId": "ea35805f-9ad7-4de5-fa85-a712815f6e96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP A/DT fastly/RB running/VBG beautiful/JJ deer/NN)\n",
      "  (VP skidded/VBD off/IN (NP the/DT road/NN)))\n"
     ]
    }
   ],
   "source": [
    "# Parsing using regular expression with chunking (without chinking)\n",
    "\n",
    "# We specify that noun phrase can have a determinant, adverb, gerund verb, or an adjective,\n",
    "# but it must have a noun or a pronoun, e.g. \"A fastly running beautiful deer...\"\n",
    "# The verb phrase should start with a verb, and then it can have anything.\n",
    "\n",
    "pattern = \"\"\"NP: {<DT>?<RB.?>?<VBG>?<JJ.?>*(<NN.?>|<PRP.?>)+}\n",
    "             VP: {<VB.?>+<.*>*}\n",
    "\"\"\"\n",
    "\n",
    "mySentence = 'A fastly running beautiful deer skidded off the road'\n",
    "\n",
    "myParser = nltk.RegexpParser(pattern)\n",
    "myParsedSentence = myParser.parse(nltk.pos_tag(nltk.word_tokenize(mySentence)))\n",
    "#myParsedSentence = myParser.parse(nltk.pos_tag(nltk.word_tokenize('The cat was going to eat bread but then he found a mouse')))\n",
    "print(myParsedSentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JwMuU4Ub1G53",
    "outputId": "3d138519-1271-4fd3-e0f0-0511e3014238",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg baseProfile=\"full\" height=\"216px\" preserveAspectRatio=\"xMidYMid meet\" style=\"font-family: times, serif; font-weight: normal; font-style: normal; font-size: 16px;\" version=\"1.1\" viewBox=\"0,0,504.0,216.0\" width=\"504px\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:ev=\"http://www.w3.org/2001/xml-events\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">S</text></svg><svg width=\"60.3175%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NP</text></svg><svg width=\"10.5263%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">A</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">DT</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"5.26316%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"21.0526%\" x=\"10.5263%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">fastly</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">RB</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"21.0526%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"23.6842%\" x=\"31.5789%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">running</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">VBG</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"43.4211%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"28.9474%\" x=\"55.2632%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">beautiful</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">JJ</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"69.7368%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"15.7895%\" x=\"84.2105%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">deer</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"92.1053%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"30.1587%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"39.6825%\" x=\"60.3175%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">VP</text></svg><svg width=\"36%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">skidded</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">VBD</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"18%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"20%\" x=\"36%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">off</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">IN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"46%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"44%\" x=\"56%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NP</text></svg><svg width=\"45.4545%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">the</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">DT</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"22.7273%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"54.5455%\" x=\"45.4545%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">road</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"72.7273%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"78%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"80.1587%\" y1=\"19.2px\" y2=\"48px\" /></svg>"
      ],
      "text/plain": [
       "Tree('S', [Tree('NP', [('A', 'DT'), ('fastly', 'RB'), ('running', 'VBG'), ('beautiful', 'JJ'), ('deer', 'NN')]), Tree('VP', [('skidded', 'VBD'), ('off', 'IN'), Tree('NP', [('the', 'DT'), ('road', 'NN')])])])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!pip install svgling\n",
    "# Displaying a parse (syntax) tree. \n",
    "# Install Ghostscript: In Anacodna prompt, type 'conda install -c conda-forge ghostscript' \n",
    "\n",
    "# This cell will not work in Google Colab\n",
    "\n",
    "from IPython.display import display\n",
    "display(myParsedSentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 978,
     "status": "ok",
     "timestamp": 1581771371704,
     "user": {
      "displayName": "Sarbind Gupta",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCX_PdUc-oYjLw3bTTsusGGiLA4h-CJUT94gBbkRw=s64",
      "userId": "14604457747665098998"
     },
     "user_tz": -330
    },
    "id": "jzGGIbHwxWEO",
    "outputId": "bfdc677c-98ed-4fb7-cfe3-edc62fe26fa0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S (NP I/PRP) (VP left/VBD to/TO do/VB (NP my/PRP$ homework/NN)))\n"
     ]
    }
   ],
   "source": [
    "# Let us try another sentence with chunking (without chinking)\n",
    "\n",
    "mySentence = 'I left to do my homework'\n",
    "\n",
    "myParser = nltk.RegexpParser(pattern)\n",
    "myParsedSentence = myParser.parse(nltk.pos_tag(nltk.word_tokenize(mySentence)))\n",
    "print(myParsedSentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fz1cGEGf1G6A",
    "outputId": "391d30ec-8d9c-43be-e59f-e06a9b48e555"
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg baseProfile=\"full\" height=\"216px\" preserveAspectRatio=\"xMidYMid meet\" style=\"font-family: times, serif; font-weight: normal; font-style: normal; font-size: 16px;\" version=\"1.1\" viewBox=\"0,0,280.0,216.0\" width=\"280px\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:ev=\"http://www.w3.org/2001/xml-events\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">S</text></svg><svg width=\"14.2857%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NP</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">I</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">PRP</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"7.14286%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"85.7143%\" x=\"14.2857%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">VP</text></svg><svg width=\"20%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">left</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">VBD</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"10%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"13.3333%\" x=\"20%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">to</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">TO</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"26.6667%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"13.3333%\" x=\"33.3333%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">do</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">VB</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"40%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"53.3333%\" x=\"46.6667%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NP</text></svg><svg width=\"37.5%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">my</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">PRP$</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"18.75%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"62.5%\" x=\"37.5%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">homework</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"68.75%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"73.3333%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"57.1429%\" y1=\"19.2px\" y2=\"48px\" /></svg>"
      ],
      "text/plain": [
       "Tree('S', [Tree('NP', [('I', 'PRP')]), Tree('VP', [('left', 'VBD'), ('to', 'TO'), ('do', 'VB'), Tree('NP', [('my', 'PRP$'), ('homework', 'NN')])])])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This cell will not work in Google Colab\n",
    "\n",
    "display(myParsedSentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package reuters to\n",
      "[nltk_data]     /Users/vidyadharbendre/nltk_data...\n",
      "[nltk_data]   Package reuters is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import reuters\n",
    "import svgling\n",
    "\n",
    "# Example usage\n",
    "nltk.download('reuters')\n",
    "#print(reuters.fileids())\n",
    "\n",
    "# Example tree drawing\n",
    "from nltk.tree import Tree\n",
    "tree = Tree.fromstring('(S (NP this tree) (VP (V is) (AdjP pretty)))')\n",
    "#tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 880,
     "status": "ok",
     "timestamp": 1581769727331,
     "user": {
      "displayName": "Sarbind Gupta",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCX_PdUc-oYjLw3bTTsusGGiLA4h-CJUT94gBbkRw=s64",
      "userId": "14604457747665098998"
     },
     "user_tz": -330
    },
    "id": "WaOfnDUOxWEW",
    "outputId": "53a1e41f-8137-4e18-9c9d-89a35a0ee7a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S (NP I/PRP) (VP left/VBD) to/TO do/VB (NP my/PRP$ homework/NN))\n"
     ]
    }
   ],
   "source": [
    "# Parsing using regular expression with chunking and chinking (exclusion rule)\n",
    "\n",
    "# Redefine pattern with chinking, to exclude \"to do something\"\n",
    "pattern = \"\"\"NP: {<DT>?<RB.?>?<VBG>?<JJ.?>*(<NN.?>|<PRP.?>)+}\n",
    "             VP: {<VB.?>+<.*>*}\n",
    "                 }(<VBG>|(<TO><.*>*)){\n",
    "\"\"\"\n",
    "\n",
    "mySentence = 'I left to do my homework'\n",
    "\n",
    "myParser = nltk.RegexpParser(pattern)\n",
    "myParsedSentence = myParser.parse(nltk.pos_tag(nltk.word_tokenize(mySentence)))\n",
    "print(myParsedSentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JoEb8num1G6H",
    "outputId": "4c3479b5-616a-423a-ae16-e632ddf28009"
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg baseProfile=\"full\" height=\"168px\" preserveAspectRatio=\"xMidYMid meet\" style=\"font-family: times, serif; font-weight: normal; font-style: normal; font-size: 16px;\" version=\"1.1\" viewBox=\"0,0,280.0,168.0\" width=\"280px\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:ev=\"http://www.w3.org/2001/xml-events\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">S</text></svg><svg width=\"14.2857%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NP</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">I</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">PRP</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"7.14286%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"17.1429%\" x=\"14.2857%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">VP</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">left</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">VBD</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"22.8571%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"11.4286%\" x=\"31.4286%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">to</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">TO</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"37.1429%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"11.4286%\" x=\"42.8571%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">do</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">VB</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"48.5714%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"45.7143%\" x=\"54.2857%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NP</text></svg><svg width=\"37.5%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">my</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">PRP$</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"18.75%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"62.5%\" x=\"37.5%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">homework</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"68.75%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"77.1429%\" y1=\"19.2px\" y2=\"48px\" /></svg>"
      ],
      "text/plain": [
       "Tree('S', [Tree('NP', [('I', 'PRP')]), Tree('VP', [('left', 'VBD')]), ('to', 'TO'), ('do', 'VB'), Tree('NP', [('my', 'PRP$'), ('homework', 'NN')])])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This cell will not work in Google Colab\n",
    "\n",
    "display(myParsedSentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2sZO3CZcxWEb"
   },
   "source": [
    "## Context\n",
    "<a id=\"Context\"></a>\n",
    "Here is some content Free Grammer section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1007,
     "status": "ok",
     "timestamp": 1581771616599,
     "user": {
      "displayName": "Sarbind Gupta",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCX_PdUc-oYjLw3bTTsusGGiLA4h-CJUT94gBbkRw=s64",
      "userId": "14604457747665098998"
     },
     "user_tz": -330
    },
    "id": "VgSVCpXzxWEc",
    "outputId": "f1e1a03f-a6a6-4b29-df6e-fb0072603207"
   },
   "outputs": [],
   "source": [
    "# Defining a grammar\n",
    "from nltk import CFG\n",
    "\n",
    "myGrammar = nltk.CFG.fromstring(\"\"\"\n",
    "    S -> NP VP\n",
    "    VP -> VB NP\n",
    "    VP -> VB\n",
    "    VP -> VB PRP\n",
    "    NP -> DET NN\n",
    "    \n",
    "    VB -> \"chased\"|\"ate\"\n",
    "    DET -> \"another\"|\"the\"\n",
    "    NN -> \"cat\"|\"rat\"|\"snake\"\n",
    "    PRP -> \"it\"\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "# Generating sentences from the defined grammar\n",
    "\n",
    "from nltk.parse.generate import generate\n",
    "\n",
    "# for sent in generate(myGrammar):\n",
    "#     print(' '.join(sent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "60Byit-CxWEf"
   },
   "source": [
    "## Frequency\n",
    "<a id=\"Frequency\"></a>\n",
    "Here is some content for the Frequency of words, bi-grams and tri-grams section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1037,
     "status": "ok",
     "timestamp": 1581771669765,
     "user": {
      "displayName": "Sarbind Gupta",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCX_PdUc-oYjLw3bTTsusGGiLA4h-CJUT94gBbkRw=s64",
      "userId": "14604457747665098998"
     },
     "user_tz": -330
    },
    "id": "iIVgLK9FxWEg",
    "outputId": "a2d84b55-4e5a-4133-e1cd-7bda38321e7a"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'wordList' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Frequency Distribution of words\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m fdist \u001b[38;5;241m=\u001b[39m nltk\u001b[38;5;241m.\u001b[39mFreqDist(\u001b[43mwordList\u001b[49m)\n\u001b[1;32m      5\u001b[0m fdist\n",
      "\u001b[0;31mNameError\u001b[0m: name 'wordList' is not defined"
     ]
    }
   ],
   "source": [
    "# Frequency Distribution of words\n",
    "\n",
    "fdist = nltk.FreqDist(wordList)\n",
    "\n",
    "fdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1017,
     "status": "ok",
     "timestamp": 1581771722867,
     "user": {
      "displayName": "Sarbind Gupta",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCX_PdUc-oYjLw3bTTsusGGiLA4h-CJUT94gBbkRw=s64",
      "userId": "14604457747665098998"
     },
     "user_tz": -330
    },
    "id": "crfq_S2VxWEj",
    "outputId": "0f8fefbf-d7fa-4b04-ffe7-deff1ff2505a"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokens' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Some n-gram examples in NLTK\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ngrams\n\u001b[0;32m----> 5\u001b[0m bigrams \u001b[38;5;241m=\u001b[39m ngrams(\u001b[43mtokens\u001b[49m,\u001b[38;5;241m2\u001b[39m) \u001b[38;5;66;03m# A bigram is specified by 2, trigram by 3, etc.\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# for b in bigrams:\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m#     print(b)\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tokens' is not defined"
     ]
    }
   ],
   "source": [
    "# Some n-gram examples in NLTK\n",
    "\n",
    "from nltk.util import ngrams\n",
    "\n",
    "bigrams = ngrams(tokens,2) # A bigram is specified by 2, trigram by 3, etc.\n",
    "# for b in bigrams:\n",
    "#     print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1263,
     "status": "ok",
     "timestamp": 1581771757405,
     "user": {
      "displayName": "Sarbind Gupta",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCX_PdUc-oYjLw3bTTsusGGiLA4h-CJUT94gBbkRw=s64",
      "userId": "14604457747665098998"
     },
     "user_tz": -330
    },
    "id": "2rp3udYExWEm",
    "outputId": "6587e469-e36a-4de4-b8b6-843f6089aeef"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokens' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trigrams \u001b[38;5;241m=\u001b[39m ngrams(\u001b[43mtokens\u001b[49m,\u001b[38;5;241m3\u001b[39m) \u001b[38;5;66;03m# A bigram is specified by 2, trigram by 3, etc.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# for t in trigrams:\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#     print(t)\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tokens' is not defined"
     ]
    }
   ],
   "source": [
    "trigrams = ngrams(tokens,3) # A bigram is specified by 2, trigram by 3, etc.\n",
    "# for t in trigrams:\n",
    "#     print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Oa7p8sucxWEp"
   },
   "source": [
    "## Stemming Lemmatization\n",
    "<a id=\"Stemming-Lemmatization\"></a>\n",
    "Here is some content for the Stemming Lemmatization section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1165,
     "status": "ok",
     "timestamp": 1581771890013,
     "user": {
      "displayName": "Sarbind Gupta",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCX_PdUc-oYjLw3bTTsusGGiLA4h-CJUT94gBbkRw=s64",
      "userId": "14604457747665098998"
     },
     "user_tz": -330
    },
    "id": "k7ybqUuYxWEq",
    "outputId": "b8123abe-e452-4349-fc19-6e48741e2a68"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     /Users/vidyadharbendre/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Comparing stemming and lemmatization\n",
    "# Reading corpus and removing stop words\n",
    "nltk.download('brown')\n",
    "from nltk.corpus import brown\n",
    "fileid = 'ck23'\n",
    "\n",
    "from nltk.corpus import stopwords # Remove stop words\n",
    "wordList = [w for w in brown.words(fileid) if w.lower() not in stopwords.words('english')]\n",
    "\n",
    "import string # Remove punctuation\n",
    "wordList = [w for w in wordList if w not in string.punctuation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1293,
     "status": "ok",
     "timestamp": 1581771954820,
     "user": {
      "displayName": "Sarbind Gupta",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCX_PdUc-oYjLw3bTTsusGGiLA4h-CJUT94gBbkRw=s64",
      "userId": "14604457747665098998"
     },
     "user_tz": -330
    },
    "id": "SJhwY8_ixWEs",
    "outputId": "e0b9ba9e-bb41-416e-e106-56ee2139bbf7"
   },
   "outputs": [],
   "source": [
    "# COMPARE TWO STEMMERS\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import LancasterStemmer\n",
    "porter = PorterStemmer()\n",
    "lancaster = LancasterStemmer()\n",
    "\n",
    "StemmersCompared = [word+' : '+porter.stem(word)+' : '+lancaster.stem(word) for word in wordList]\n",
    "#StemmersCompared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "wordNet = WordNetLemmatizer()\n",
    "from nltk.stem.api import StemmerI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 828,
     "status": "ok",
     "timestamp": 1581769771456,
     "user": {
      "displayName": "Sarbind Gupta",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCX_PdUc-oYjLw3bTTsusGGiLA4h-CJUT94gBbkRw=s64",
      "userId": "14604457747665098998"
     },
     "user_tz": -330
    },
    "id": "fEBSf6glxWEu",
    "outputId": "2964a58c-59c0-4685-a07c-1a50e8dda243"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['though : though : though : though',\n",
       " 'noted : note : not : noted',\n",
       " 'clearly : clearli : clear : clearly',\n",
       " 'nephews : nephew : nephew : nephew',\n",
       " 'see : see : see : see',\n",
       " 'ten : ten : ten : ten',\n",
       " 'years : year : year : year',\n",
       " 'since : sinc : sint : since',\n",
       " 'last : last : last : last',\n",
       " 'journey : journey : journey : journey',\n",
       " 'eastward : eastward : eastward : eastward',\n",
       " 'witness : wit : wit : witness',\n",
       " 'Uncle : uncl : unc : Uncle',\n",
       " 'Izaak : izaak : izaak : Izaak',\n",
       " 'lowered : lower : low : lowered',\n",
       " 'rocky : rocki : rocky : rocky',\n",
       " 'soil : soil : soil : soil',\n",
       " 'aside : asid : asid : aside',\n",
       " 'due : due : due : due',\n",
       " 'notification : notif : not : notification',\n",
       " 'certain : certain : certain : certain',\n",
       " 'major : major : maj : major',\n",
       " 'events : event : ev : event',\n",
       " 'lives : live : liv : life',\n",
       " 'two : two : two : two',\n",
       " 'marriages : marriag : marry : marriage',\n",
       " 'two : two : two : two',\n",
       " 'births : birth : birth : birth',\n",
       " 'one : one : on : one',\n",
       " 'divorce : divorc : divorc : divorce',\n",
       " 'Christmas : christma : christmas : Christmas',\n",
       " 'Easter : easter : east : Easter',\n",
       " 'cards : card : card : card',\n",
       " 'traditional : tradit : tradit : traditional',\n",
       " 'sort : sort : sort : sort',\n",
       " 'thin : thin : thin : thin',\n",
       " 'link : link : link : link',\n",
       " 'widowed : widow : widow : widowed',\n",
       " 'years : year : year : year',\n",
       " 'thoughts : thought : thought : thought',\n",
       " 'discrete : discret : discret : discrete',\n",
       " 'look : look : look : look',\n",
       " 'mouth : mouth : mou : mouth',\n",
       " 'though : though : though : though',\n",
       " 'tasting : tast : tast : tasting',\n",
       " 'lemons : lemon : lemon : lemon',\n",
       " 'grasped : grasp : grasp : grasped',\n",
       " 'chair : chair : chair : chair',\n",
       " 'arms : arm : arm : arm',\n",
       " 'brought : brought : brought : brought',\n",
       " 'thin : thin : thin : thin',\n",
       " 'body : bodi : body : body',\n",
       " 'upright : upright : upright : upright',\n",
       " 'like : like : lik : like',\n",
       " 'bird : bird : bird : bird',\n",
       " 'alert : alert : alert : alert',\n",
       " 'flight : flight : flight : flight',\n",
       " 'turned : turn : turn : turned',\n",
       " 'walked : walk : walk : walked',\n",
       " 'stiffly : stiffli : stiff : stiffly',\n",
       " 'parlor : parlor : parl : parlor',\n",
       " 'dainty-legged : dainty-leg : dainty-legged : dainty-legged',\n",
       " 'escritoire : escritoir : escritoir : escritoire',\n",
       " 'warped : warp : warp : warped',\n",
       " 'cracked : crack : crack : cracked',\n",
       " 'fifty : fifti : fifty : fifty',\n",
       " 'years : year : year : year',\n",
       " 'atmosphere : atmospher : atmosph : atmosphere',\n",
       " 'sea : sea : sea : sea',\n",
       " 'spray : spray : spray : spray',\n",
       " 'extracted : extract : extract : extracted',\n",
       " 'two : two : two : two',\n",
       " 'limp : limp : limp : limp',\n",
       " 'vellum : vellum : vell : vellum',\n",
       " 'sheets : sheet : sheet : sheet',\n",
       " 'wrote : wrote : wrot : wrote',\n",
       " 'letters : letter : let : letter',\n",
       " 'one : one : on : one',\n",
       " 'Abel : abel : abel : Abel',\n",
       " 'one : one : on : one',\n",
       " 'Mark : mark : mark : Mark',\n",
       " 'trembling : trembl : trembl : trembling',\n",
       " 'hand : hand : hand : hand',\n",
       " 'pen : pen : pen : pen',\n",
       " 'grasped : grasp : grasp : grasped',\n",
       " 'tight : tight : tight : tight',\n",
       " 'pressed : press : press : pressed',\n",
       " 'paper : paper : pap : paper',\n",
       " 'words : word : word : word',\n",
       " 'came : came : cam : came',\n",
       " 'sharply : sharpli : sharply : sharply',\n",
       " 'smoothly : smoothli : smooth : smoothly',\n",
       " 'authoritatively : authorit : authorit : authoritatively',\n",
       " 'would : would : would : would',\n",
       " 'dropping : drop : drop : dropping',\n",
       " 'lips : lip : lip : lip',\n",
       " 'stiffly : stiffli : stiff : stiffly',\n",
       " 'regal : regal : reg : regal',\n",
       " 'look : look : look : look',\n",
       " 'saw : saw : saw : saw',\n",
       " 'grimly : grimli : grim : grimly',\n",
       " 'lacked : lack : lack : lacked',\n",
       " 'quaver : quaver : quav : quaver',\n",
       " 'age : age : ag : age',\n",
       " 'thwarting : thwart : thwarting : thwarting',\n",
       " 'efforts : effort : effort : effort',\n",
       " 'amazing : amaz : amaz : amazing',\n",
       " 'ran : ran : ran : ran',\n",
       " 'spoken : spoken : spok : spoken',\n",
       " 'words : word : word : word',\n",
       " 'like : like : lik : like',\n",
       " 'thin : thin : thin : thin',\n",
       " 'ragged : rag : rag : ragged',\n",
       " 'string : string : string : string',\n",
       " '`` : `` : `` : ``',\n",
       " 'Please : pleas : pleas : Please',\n",
       " 'come : come : com : come',\n",
       " 'soon : soon : soon : soon',\n",
       " 'conveniently : conveni : conveny : conveniently',\n",
       " \"'' : '' : '' : ''\",\n",
       " 'upright : upright : upright : upright',\n",
       " 'letters : letter : let : letter',\n",
       " 'stalked : stalk : stalk : stalked',\n",
       " 'broad-nibbed : broad-nib : broad-nibb : broad-nibbed',\n",
       " 'pen : pen : pen : pen',\n",
       " '`` : `` : `` : ``',\n",
       " 'important : import : import : important',\n",
       " 'matter : matter : mat : matter',\n",
       " 'discuss : discuss : discuss : discus',\n",
       " \"'' : '' : '' : ''\",\n",
       " 'Abel : abel : abel : Abel',\n",
       " '`` : `` : `` : ``',\n",
       " 'afraid : afraid : afraid : afraid',\n",
       " 'much : much : much : much',\n",
       " 'amuse : amus : amus : amuse',\n",
       " 'small : small : smal : small',\n",
       " 'children : children : childr : child',\n",
       " 'obliged : oblig : oblig : obliged',\n",
       " 'could : could : could : could',\n",
       " 'make : make : mak : make',\n",
       " 'arrangements : arrang : arrang : arrangement',\n",
       " 'daughters : daughter : daught : daughter',\n",
       " 'may : may : may : may',\n",
       " 'stay : stay : stay : stay',\n",
       " 'long : long : long : long',\n",
       " 'wish : wish : wish : wish',\n",
       " 'course : cours : cours : course',\n",
       " 'arranging : arrang : arrang : arranging',\n",
       " 'care : care : car : care',\n",
       " 'girls : girl : girl : girl',\n",
       " 'must : must : must : must',\n",
       " 'take : take : tak : take',\n",
       " 'time : time : tim : time',\n",
       " 'account : account : account : account',\n",
       " 'think : think : think : think',\n",
       " 'day : day : day : day',\n",
       " 'two : two : two : two',\n",
       " 'enough : enough : enough : enough',\n",
       " 'finish : finish : fin : finish',\n",
       " 'business : busi : busy : business',\n",
       " \"'' : '' : '' : ''\",\n",
       " 'Mark : mark : mark : Mark',\n",
       " '`` : `` : `` : ``',\n",
       " 'Please : pleas : pleas : Please',\n",
       " 'give : give : giv : give',\n",
       " 'regards : regard : regard : regard',\n",
       " 'Myra : myra : myr : Myra',\n",
       " \"'' : '' : '' : ''\",\n",
       " 'signed : sign : sign : signed',\n",
       " 'letters : letter : let : letter',\n",
       " 'quickly : quickli : quick : quickly',\n",
       " 'stamped : stamp : stamp : stamped',\n",
       " 'placed : place : plac : placed',\n",
       " 'hall : hall : hal : hall',\n",
       " 'table : tabl : tabl : table',\n",
       " 'Raphael : raphael : raphael : Raphael',\n",
       " 'mail : mail : mail : mail',\n",
       " 'town : town : town : town',\n",
       " 'went : went : went : went',\n",
       " 'back : back : back : back',\n",
       " 'wicker : wicker : wick : wicker',\n",
       " 'chair : chair : chair : chair',\n",
       " 'resolutely : resolut : resolv : resolutely',\n",
       " 'adjusted : adjust : adjust : adjusted',\n",
       " 'eyes : eye : ey : eye',\n",
       " 'glare : glare : glar : glare',\n",
       " 'water : water : wat : water',\n",
       " '`` : `` : `` : ``',\n",
       " 'nephews : nephew : nephew : nephew',\n",
       " 'coming : come : com : coming',\n",
       " \"'' : '' : '' : ''\",\n",
       " 'said : said : said : said',\n",
       " 'evening : even : ev : evening',\n",
       " 'Angelina : angelina : angelin : Angelina',\n",
       " 'brought : brought : brought : brought',\n",
       " 'dinner : dinner : din : dinner',\n",
       " 'dining : dine : din : dining',\n",
       " 'room : room : room : room',\n",
       " 'whole : whole : whol : whole',\n",
       " 'meal : meal : meal : meal',\n",
       " 'vast : vast : vast : vast',\n",
       " 'linen-covered : linen-cov : linen-covered : linen-covered',\n",
       " 'tray : tray : tray : tray',\n",
       " 'looked : look : look : looked',\n",
       " 'girl : girl : girl : girl',\n",
       " 'speculatively : specul : spec : speculatively',\n",
       " 'eyes : eye : ey : eye',\n",
       " 'paled : pale : pal : paled',\n",
       " 'years : year : year : year',\n",
       " 'early : earli : ear : early',\n",
       " 'evening : even : ev : evening',\n",
       " 'lights : light : light : light',\n",
       " 'first : first : first : first',\n",
       " 'startled : startl : startl : startled',\n",
       " 'Izaak : izaak : izaak : Izaak',\n",
       " 'look : look : look : look',\n",
       " 'uncousinly : uncousinli : uncousin : uncousinly',\n",
       " 'way : way : way : way',\n",
       " 'faded : fade : fad : faded',\n",
       " 'near-absence : near-abs : near-absence : near-absence',\n",
       " 'color : color : col : color',\n",
       " 'possibly : possibl : poss : possibly',\n",
       " 'constant : constant : const : constant',\n",
       " 'looking : look : look : looking',\n",
       " 'water : water : wat : water',\n",
       " 'something : someth : someth : something',\n",
       " 'light : light : light : light',\n",
       " 'sea : sea : sea : sea',\n",
       " 'Angelina : angelina : angelin : Angelina',\n",
       " 'placed : place : plac : placed',\n",
       " 'tray : tray : tray : tray',\n",
       " 'table : tabl : tabl : table',\n",
       " 'flick : flick : flick : flick',\n",
       " 'dark : dark : dark : dark',\n",
       " 'wrist : wrist : wrist : wrist',\n",
       " 'drew : drew : drew : drew',\n",
       " 'cloth : cloth : clo : cloth',\n",
       " 'smiled : smile : smil : smiled',\n",
       " 'teeth : teeth : tee : teeth',\n",
       " 'gleamed : gleam : gleam : gleamed',\n",
       " 'beautifully : beauti : beauty : beautifully',\n",
       " 'modeled : model : model : modeled',\n",
       " 'olive : oliv : ol : olive',\n",
       " 'face : face : fac : face',\n",
       " '`` : `` : `` : ``',\n",
       " 'nice : nice : nic : nice',\n",
       " 'Mrs. : mrs. : mrs. : Mrs.',\n",
       " 'Packard : packard : packard : Packard',\n",
       " \"'' : '' : '' : ''\",\n",
       " 'said : said : said : said',\n",
       " 'voice : voic : voic : voice',\n",
       " 'ripe : ripe : rip : ripe',\n",
       " 'full : full : ful : full',\n",
       " 'teeth : teeth : tee : teeth',\n",
       " 'flashed : flash : flash : flashed',\n",
       " 'Sicilian : sicilian : sicil : Sicilian',\n",
       " 'brilliance : brillianc : bril : brilliance',\n",
       " 'warm : warm : warm : warm',\n",
       " 'curved : curv : curv : curved',\n",
       " 'lips : lip : lip : lip',\n",
       " 'met : met : met : met',\n",
       " 'mouth : mouth : mou : mouth',\n",
       " 'settled : settl : settl : settled',\n",
       " 'repose : repos : repos : repose',\n",
       " '`` : `` : `` : ``',\n",
       " 'Um : um : um : Um',\n",
       " \"'' : '' : '' : ''\",\n",
       " 'said : said : said : said',\n",
       " 'old : old : old : old',\n",
       " 'lady : ladi : lady : lady',\n",
       " 'brought : brought : brought : brought',\n",
       " 'eyes : eye : ey : eye',\n",
       " 'tray : tray : tray : tray',\n",
       " '`` : `` : `` : ``',\n",
       " 'remember : rememb : rememb : remember',\n",
       " 'suppose : suppos : suppos : suppose',\n",
       " \"'' : '' : '' : ''\",\n",
       " 'glinted : glint : glint : glinted',\n",
       " 'suspiciously : suspici : suspicy : suspiciously',\n",
       " 'dish : dish : dish : dish',\n",
       " '`` : `` : `` : ``',\n",
       " 'blowfish : blowfish : blowf : blowfish',\n",
       " 'hope : hope : hop : hope',\n",
       " 'Raphael : raphael : raphael : Raphael',\n",
       " 'bought : bought : bought : bought',\n",
       " 'whole : whole : whol : whole',\n",
       " \"'' : '' : '' : ''\",\n",
       " 'Angelina : angelina : angelin : Angelina',\n",
       " 'stepped : step : step : stepped',\n",
       " 'back : back : back : back',\n",
       " 'eyes : eye : ey : eye',\n",
       " 'roaming : roam : roam : roaming',\n",
       " 'tray : tray : tray : tray',\n",
       " 'omissions : omiss : omit : omission',\n",
       " 'looked : look : look : looked',\n",
       " 'old : old : old : old',\n",
       " 'woman : woman : wom : woman',\n",
       " 'eyes : eye : ey : eye',\n",
       " 'calm : calm : calm : calm',\n",
       " '`` : `` : `` : ``',\n",
       " 'Yes : ye : ye : Yes',\n",
       " \"'' : '' : '' : ''\",\n",
       " 'said : said : said : said',\n",
       " '`` : `` : `` : ``',\n",
       " 'remember : rememb : rememb : remember',\n",
       " 'came : came : cam : came',\n",
       " 'every : everi : every : every',\n",
       " 'summer : summer : sum : summer',\n",
       " 'used : use : us : used',\n",
       " 'play : play : play : play',\n",
       " 'older : older : old : older',\n",
       " 'one : one : on : one',\n",
       " 'sometimes : sometim : sometim : sometimes',\n",
       " \"he'd : he'd : he'd : he'd\",\n",
       " 'let : let : let : let',\n",
       " 'Abel : abel : abel : Abel',\n",
       " \"'' : '' : '' : ''\",\n",
       " 'name : name : nam : name',\n",
       " 'fell : fell : fel : fell',\n",
       " 'lazy : lazi : lazy : lazy',\n",
       " 'affectionate : affection : affect : affectionate',\n",
       " 'remembrance : remembr : remembr : remembrance',\n",
       " 'lips : lip : lip : lip',\n",
       " 'instant : instant : inst : instant',\n",
       " 'old : old : old : old',\n",
       " 'aunt : aunt : aunt : aunt',\n",
       " 'felt : felt : felt : felt',\n",
       " 'something : someth : someth : something',\n",
       " 'indefinable : indefin : indefin : indefinable',\n",
       " 'flash : flash : flash : flash',\n",
       " 'smile : smile : smil : smile',\n",
       " 'would : would : would : would',\n",
       " 'said : said : said : said',\n",
       " 'triumph : triumph : triumph : triumph',\n",
       " 'Angelina : angelina : angelin : Angelina',\n",
       " 'turned : turn : turn : turned',\n",
       " 'easy : easi : easy : easy',\n",
       " 'grace : grace : grac : grace',\n",
       " 'walked : walk : walk : walked',\n",
       " 'toward : toward : toward : toward',\n",
       " 'kitchen : kitchen : kitch : kitchen',\n",
       " 'Jessica : jessica : jessic : Jessica',\n",
       " 'Packard : packard : packard : Packard',\n",
       " 'lifted : lift : lift : lifted',\n",
       " 'head : head : head : head',\n",
       " 'followed : follow : follow : followed',\n",
       " 'retreating : retreat : ret : retreating',\n",
       " 'figure : figur : fig : figure',\n",
       " 'eyes : eye : ey : eye',\n",
       " 'resting : rest : rest : resting',\n",
       " 'nearly : nearli : near : nearly',\n",
       " 'closed : close : clos : closed',\n",
       " 'unself-conscious : unself-consci : unself-conscious : unself-conscious',\n",
       " 'rise : rise : ris : rise',\n",
       " 'fall : fall : fal : fall',\n",
       " 'rounded : round : round : rounded',\n",
       " 'hips : hip : hip : hip',\n",
       " 'moment : moment : mom : moment',\n",
       " 'held : held : held : held',\n",
       " 'face : face : fac : face',\n",
       " 'empty : empti : empty : empty',\n",
       " 'doorway : doorway : doorway : doorway',\n",
       " 'snorted : snort : snort : snorted',\n",
       " 'groped : grope : grop : groped',\n",
       " 'fork : fork : fork : fork',\n",
       " \"There's : there' : there's : There's\",\n",
       " 'greater : greater : gre : greater',\n",
       " 'catastrophe : catastroph : catastroph : catastrophe',\n",
       " 'universe : univers : univers : universe',\n",
       " 'reflected : reflect : reflect : reflected',\n",
       " 'dourly : dourli : dour : dourly',\n",
       " 'impaling : impal : imp : impaling',\n",
       " 'tender : tender : tend : tender',\n",
       " 'green : green : green : green',\n",
       " 'beans : bean : bean : bean',\n",
       " 'silver : silver : silv : silver',\n",
       " 'fork : fork : fork : fork',\n",
       " 'dwindling : dwindl : dwindl : dwindling',\n",
       " 'away : away : away : away',\n",
       " 'family : famili : famy : family',\n",
       " 'Procreation : procreat : procr : Procreation',\n",
       " 'expansion : expans : expand : expansion',\n",
       " 'proliferation : prolifer : prol : proliferation',\n",
       " '-- : -- : -- : --',\n",
       " 'laws : law : law : law',\n",
       " 'living : live : liv : living',\n",
       " 'things : thing : thing : thing',\n",
       " 'penalty : penalti : penal : penalty',\n",
       " 'obeying : obey : obey : obeying',\n",
       " 'ultimate : ultim : ultim : ultimate',\n",
       " 'punishments : punish : pun : punishment',\n",
       " 'oblivion : oblivion : obl : oblivion',\n",
       " 'fate : fate : fat : fate',\n",
       " 'individual : individu : individ : individual',\n",
       " 'visited : visit : visit : visited',\n",
       " 'group : group : group : group',\n",
       " 'warm : warm : warm : warm',\n",
       " 'sweet : sweet : sweet : sweet',\n",
       " 'butter : butter : but : butter',\n",
       " 'dripped : drip : drip : dripped',\n",
       " 'raised : rais : rais : raised',\n",
       " 'trembling : trembl : trembl : trembling',\n",
       " 'fork : fork : fork : fork',\n",
       " 'pushed : push : push : pushed',\n",
       " 'head : head : head : head',\n",
       " 'forward : forward : forward : forward',\n",
       " 'belligerently : belliger : bellig : belligerently',\n",
       " 'ah : ah : ah : ah',\n",
       " 'true : true : tru : true',\n",
       " 'bitterness : bitter : bit : bitterness',\n",
       " 'existence : exist : ex : existence',\n",
       " 'could : could : could : could',\n",
       " 'tasted : tast : tast : tasted',\n",
       " 'indeed : inde : indee : indeed',\n",
       " 'young : young : young : young',\n",
       " 'garden : garden : gard : garden',\n",
       " 'beans : bean : bean : bean',\n",
       " 'brackish : brackish : brack : brackish',\n",
       " 'mouth : mouth : mou : mouth',\n",
       " 'last : last : last : last',\n",
       " 'living : live : liv : living',\n",
       " 'older : older : old : older',\n",
       " 'generation : gener : gen : generation',\n",
       " 'widespread : widespread : widespread : widespread',\n",
       " 'family : famili : famy : family',\n",
       " '-- : -- : -- : --',\n",
       " 'one : one : on : one',\n",
       " 'time : time : tim : time',\n",
       " 'knew : knew : knew : knew',\n",
       " 'enough : enough : enough : enough',\n",
       " 'Packards : packard : packard : Packards',\n",
       " 'populate : popul : pop : populate',\n",
       " 'entire : entir : entir : entire',\n",
       " 'county : counti : county : county',\n",
       " '-- : -- : -- : --',\n",
       " 'narrowed : narrow : narrow : narrowed',\n",
       " 'two : two : two : two',\n",
       " 'boys : boy : boy : boy',\n",
       " 'Abel : abel : abel : Abel',\n",
       " 'Mark : mark : mark : Mark',\n",
       " 'swung : swung : swung : swung',\n",
       " 'eyes : eye : ey : eye',\n",
       " 'blue : blue : blu : blue',\n",
       " 'window : window : window : window',\n",
       " 'jaws : jaw : jaw : jaw',\n",
       " 'gently : gentli : gent : gently',\n",
       " 'mashing : mash : mash : mashing',\n",
       " 'bitter : bitter : bit : bitter',\n",
       " 'beans : bean : bean : bean',\n",
       " 'hope : hope : hop : hope',\n",
       " 'lay : lay : lay : lay',\n",
       " 'nephews : nephew : nephew : nephew',\n",
       " 'asked : ask : ask : asked',\n",
       " 'intensifying : intensifi : intens : intensifying',\n",
       " 'light : light : light : light',\n",
       " 'one : one : on : one',\n",
       " 'married : marri : marry : married',\n",
       " 'barren : barren : bar : barren',\n",
       " 'woman : woman : wom : woman',\n",
       " 'divorced : divorc : divorc : divorced',\n",
       " 'sired : sire : sir : sired',\n",
       " 'two : two : two : two',\n",
       " 'girl : girl : girl : girl',\n",
       " 'children : children : childr : child',\n",
       " 'none : none : non : none',\n",
       " 'bear : bear : bear : bear',\n",
       " 'Packard : packard : packard : Packard',\n",
       " 'name : name : nam : name',\n",
       " 'ate : ate : at : ate',\n",
       " 'seemed : seem : seem : seemed',\n",
       " 'seemed : seem : seem : seemed',\n",
       " 'night : night : night : night',\n",
       " 'gloom : gloom : gloom : gloom',\n",
       " 'drew : drew : drew : drew',\n",
       " 'became : becam : becam : became',\n",
       " 'densest : densest : densest : densest',\n",
       " \"table's : table' : table's : table's\",\n",
       " 'empty : empti : empty : empty',\n",
       " 'chairs : chair : chair : chair',\n",
       " 'giving : give : giv : giving',\n",
       " 'frequent : frequent : frequ : frequent',\n",
       " 'illusion : illus : illud : illusion',\n",
       " 'dined : dine : din : dined',\n",
       " 'shadows : shadow : shadow : shadow',\n",
       " 'talked : talk : talk : talked',\n",
       " 'low : low : low : low',\n",
       " 'quirking : quirk : quirk : quirking',\n",
       " 'head : head : head : head',\n",
       " 'one : one : on : one',\n",
       " 'another : anoth : anoth : another',\n",
       " 'places : place : plac : place',\n",
       " 'often : often : oft : often',\n",
       " \"Izaak's : izaak' : izaak's : Izaak's\",\n",
       " 'armchair : armchair : armchair : armchair',\n",
       " 'faced : face : fac : faced',\n",
       " 'across : across : across : across',\n",
       " 'long : long : long : long',\n",
       " 'table : tabl : tabl : table',\n",
       " 'might : might : might : might',\n",
       " 'absent : absent : abs : absent',\n",
       " 'nephews : nephew : nephew : nephew',\n",
       " 'addressed : address : address : addressed',\n",
       " 'consciously : conscious : conscy : consciously',\n",
       " 'playing : play : play : playing',\n",
       " 'notion : notion : not : notion',\n",
       " 'one : one : on : one',\n",
       " 'summers : summer : sum : summer',\n",
       " 'early : earli : ear : early',\n",
       " 'years : year : year : year',\n",
       " 'thought : thought : thought : thought',\n",
       " 'children : children : childr : child',\n",
       " 'two : two : two : two',\n",
       " 'died : die : died : died',\n",
       " 'young : young : young : young',\n",
       " 'later : later : lat : later',\n",
       " 'science : scienc : sci : science',\n",
       " 'might : might : might : might',\n",
       " 'saved : save : sav : saved',\n",
       " 'could : could : could : could',\n",
       " 'attach : attach : attach : attach',\n",
       " 'even : even : ev : even',\n",
       " 'label : label : label : label',\n",
       " 'separate : separ : sep : separate',\n",
       " 'malignancies : malign : malign : malignancy',\n",
       " 'girl : girl : girl : girl',\n",
       " 'first : first : first : first',\n",
       " 'barely : bare : bar : barely',\n",
       " 'remembered : rememb : rememb : remembered',\n",
       " 'could : could : could : could',\n",
       " \"anyone's : anyone' : anyone's : anyone's\",\n",
       " 'infant : infant : inf : infant',\n",
       " 'survived : surviv : surv : survived',\n",
       " 'bassinet : bassinet : bassinet : bassinet',\n",
       " 'boy : boy : boy : boy',\n",
       " 'boy : boy : boy : boy',\n",
       " 'alive : aliv : al : alive',\n",
       " 'yesterday : yesterday : yesterday : yesterday',\n",
       " 'successive : success : success : successive',\n",
       " 'movement : movement : mov : movement',\n",
       " 'growing : grow : grow : growing',\n",
       " 'recorded : record : record : recorded',\n",
       " 'unreeling : unreel : unreel : unreeling',\n",
       " 'film : film : film : film',\n",
       " 'inside : insid : insid : inside',\n",
       " 'ran : ran : ran : ran',\n",
       " 'plump : plump : plump : plump',\n",
       " 'sticks : stick : stick : stick',\n",
       " 'legs : leg : leg : leg',\n",
       " 'freezing : freez : freez : freezing',\n",
       " 'sudden : sudden : sud : sudden',\n",
       " 'startled : startl : startl : startled',\n",
       " 'attitudes : attitud : attitud : attitude',\n",
       " 'camera : camera : camer : camera',\n",
       " 'caught : caught : caught : caught',\n",
       " 'held : held : held : held',\n",
       " 'paling : pale : pal : paling',\n",
       " 'photographs : photograph : photograph : photograph',\n",
       " 'carefully : care : car : carefully',\n",
       " 'placed : place : plac : placed',\n",
       " 'glued : glu : glu : glued',\n",
       " 'labeled : label : label : labeled',\n",
       " 'resting : rest : rest : resting',\n",
       " 'fat : fat : fat : fat',\n",
       " 'plush : plush : plush : plush',\n",
       " 'album : album : alb : album',\n",
       " 'bottom : bottom : bottom : bottom',\n",
       " 'drawer : drawer : draw : drawer',\n",
       " 'escritoire : escritoir : escritoir : escritoire',\n",
       " 'cruel : cruel : cruel : cruel',\n",
       " 'clearness : clear : clear : clearness',\n",
       " 'memory : memori : mem : memory',\n",
       " 'boy : boy : boy : boy',\n",
       " 'remained : remain : remain : remained',\n",
       " 'unchanged : unchang : unchang : unchanged',\n",
       " 'quick : quick : quick : quick',\n",
       " 'delight : delight : delight : delight',\n",
       " 'laughter : laughter : laught : laughter',\n",
       " 'pain : pain : pain : pain',\n",
       " 'recalled : recal : recal : recalled',\n",
       " 'short : short : short : short',\n",
       " 'destroyed : destroy : destroy : destroyed',\n",
       " 'childhood : childhood : child : childhood',\n",
       " 'still : still : stil : still',\n",
       " 'unendurable : unendur : unend : unendurable',\n",
       " 'one : one : on : one',\n",
       " 'desolate : desol : desol : desolate',\n",
       " 'rocks : rock : rock : rock',\n",
       " 'alien : alien : aly : alien',\n",
       " 'water : water : wat : water',\n",
       " 'days : day : day : day',\n",
       " 'hated : hate : hat : hated',\n",
       " 'sea : sea : sea : sea',\n",
       " 'brothers : brother : broth : brother',\n",
       " 'drove : drove : drov : drove',\n",
       " 'together : togeth : togeth : together',\n",
       " \"Mark's : mark' : mark's : Mark's\",\n",
       " 'small : small : smal : small',\n",
       " 'red : red : red : red',\n",
       " 'sports : sport : sport : sport',\n",
       " 'car : car : car : car',\n",
       " 'Mark : mark : mark : Mark',\n",
       " 'wheel : wheel : wheel : wheel',\n",
       " 'rarely : rare : rar : rarely',\n",
       " 'spoke : spoke : spok : spoke',\n",
       " 'Abel : abel : abel : Abel',\n",
       " 'sat : sat : sat : sat',\n",
       " 'regarded : regard : regard : regarded',\n",
       " 'farm : farm : farm : farm',\n",
       " 'country : countri : country : country',\n",
       " 'spreading : spread : spreading : spreading',\n",
       " 'sides : side : sid : side',\n",
       " 'road : road : road : road',\n",
       " 'rolled : roll : rol : rolled',\n",
       " 'greenly : greenli : green : greenly',\n",
       " 'silent : silent : sil : silent',\n",
       " 'white : white : whit : white',\n",
       " 'houses : hous : hous : house',\n",
       " 'long : long : long : long',\n",
       " 'barns : barn : barn : barn',\n",
       " 'silos : silo : silo : silo',\n",
       " 'nested : nest : nest : nested',\n",
       " 'tilled : till : til : tilled',\n",
       " 'fields : field : field : field',\n",
       " 'saw : saw : saw : saw',\n",
       " 'land : land : land : land',\n",
       " \"stranger's : stranger' : stranger's : stranger's\",\n",
       " 'eyes : eye : ey : eye',\n",
       " 'old : old : old : old',\n",
       " 'familiarness : familiar : famili : familiarness',\n",
       " 'gone : gone : gon : gone',\n",
       " 'presented : present : pres : presented',\n",
       " 'would : would : would : would',\n",
       " 'stranger : stranger : stranger : stranger',\n",
       " 'impervious : impervi : impervy : impervious',\n",
       " 'complete : complet : complet : complete',\n",
       " 'stability : stabil : stabl : stability',\n",
       " '-- : -- : -- : --',\n",
       " 'color : color : col : color',\n",
       " 'life : life : lif : life',\n",
       " 'childhood : childhood : child : childhood',\n",
       " 'told : told : told : told',\n",
       " 'Solid : solid : solid : Solid',\n",
       " 'settled : settl : settl : settled',\n",
       " 'lost : lost : lost : lost',\n",
       " 'stiff : stiff : stiff : stiff',\n",
       " 'neutral : neutral : neut : neutral',\n",
       " 'lines : line : lin : line',\n",
       " 'telephone : telephon : telephon : telephone',\n",
       " 'poles : pole : pol : pole',\n",
       " 'saw : saw : saw : saw',\n",
       " 'no-nonsense : no-nonsens : no-nonsense : no-nonsense',\n",
       " 'pen : pen : pen : pen',\n",
       " 'strokes : stroke : strokes : stroke',\n",
       " 'Aunt : aunt : aunt : Aunt',\n",
       " \"Jessica's : jessica' : jessica's : Jessica's\",\n",
       " 'letter : letter : let : letter',\n",
       " 'bad : bad : bad : bad',\n",
       " 'grace : grace : grac : grace',\n",
       " 'incredible : incred : incred : incredible',\n",
       " 'selfishness : selfish : self : selfishness',\n",
       " 'Mark : mark : mark : Mark',\n",
       " 'shown : shown : shown : shown',\n",
       " 'boyhood : boyhood : boy : boyhood',\n",
       " 'summers : summer : sum : summer',\n",
       " 'preceding : preced : prec : preceding',\n",
       " \"uncle's : uncle' : uncle's : uncle's\",\n",
       " 'funeral : funer : fun : funeral',\n",
       " 'might : might : might : might',\n",
       " 'never : never : nev : never',\n",
       " 'closed : close : clos : closed',\n",
       " 'absolutely : absolut : absolv : absolutely',\n",
       " 'sealing : seal : seal : sealing',\n",
       " 'old : old : old : old',\n",
       " \"Izaak's : izaak' : izaak's : Izaak's\",\n",
       " 'grave : grave : grav : grave',\n",
       " 'small : small : smal : small',\n",
       " 'car : car : car : car',\n",
       " 'flew : flew : flew : flew',\n",
       " 'relentlessly : relentlessli : relentless : relentlessly',\n",
       " 'old : old : old : old',\n",
       " 'woman : woman : wom : woman',\n",
       " 'stubbornly : stubbornli : stubborn : stubbornly',\n",
       " 'reigning : reign : reign : reigning',\n",
       " 'house : hous : hous : house',\n",
       " 'crashing : crash : crash : crashing',\n",
       " 'waters : water : wat : water',\n",
       " 'took : took : took : took',\n",
       " 'ominous : omin : omin : ominous',\n",
       " 'reality : realiti : real : reality',\n",
       " 'Abel : abel : abel : Abel',\n",
       " 'moved : move : mov : moved',\n",
       " 'adjusted : adjust : adjust : adjusted',\n",
       " 'long : long : long : long',\n",
       " 'legs : leg : leg : leg',\n",
       " '`` : `` : `` : ``',\n",
       " 'suppose : suppos : suppos : suppose',\n",
       " 'property : properti : property : property',\n",
       " \"'' : '' : '' : ''\",\n",
       " 'Mark : mark : mark : Mark',\n",
       " 'said : said : said : said',\n",
       " 'telephone : telephon : telephon : telephone',\n",
       " 'discussed : discuss : discuss : discussed',\n",
       " 'receipt : receipt : receipt : receipt',\n",
       " 'letters : letter : let : letter',\n",
       " 'words : word : word : word',\n",
       " 'spoken : spoken : spok : spoken',\n",
       " 'Abel : abel : abel : Abel',\n",
       " 'suddenly : suddenli : sud : suddenly',\n",
       " 'see : see : see : see',\n",
       " 'old : old : old : old',\n",
       " 'house : hous : hous : house',\n",
       " 'insistent : insist : insist : insistent',\n",
       " 'sea : sea : sea : sea',\n",
       " 'feel : feel : feel : feel',\n",
       " 'contrition : contrit : contrit : contrition',\n",
       " 'blotted : blot : blot : blotted',\n",
       " 'one : one : on : one',\n",
       " 'shameful : shame : sham : shameful',\n",
       " 'moment : moment : mom : moment',\n",
       " 'covetousness : covet : covet : covetousness',\n",
       " 'Mark : mark : mark : Mark',\n",
       " 'last : last : last : last',\n",
       " 'family : famili : famy : family',\n",
       " 'lay : lay : lay : lay',\n",
       " 'Cape : cape : cap : Cape',\n",
       " 'Ann : ann : an : Ann',\n",
       " 'property : properti : property : property',\n",
       " 'seemed : seem : seem : seemed',\n",
       " 'end : end : end : end',\n",
       " 'stretching : stretch : stretching : stretching',\n",
       " 'horizon : horizon : horizon : horizon',\n",
       " 'horizon : horizon : horizon : horizon',\n",
       " 'golden : golden : gold : golden',\n",
       " 'days : day : day : day',\n",
       " 'summer : summer : sum : summer',\n",
       " 'Abel : abel : abel : Abel',\n",
       " 'turned : turn : turn : turned',\n",
       " 'head : head : head : head',\n",
       " 'look : look : look : look',\n",
       " 'brother : brother : broth : brother',\n",
       " 'Mark : mark : mark : Mark',\n",
       " 'held : held : held : held',\n",
       " 'wheel : wheel : wheel : wheel',\n",
       " 'loosely : loos : loos : loosely',\n",
       " 'fingers : finger : fing : finger',\n",
       " 'curved : curv : curv : curved',\n",
       " 'around : around : around : around',\n",
       " 'purposeful : purpos : purpos : purposeful',\n",
       " 'way : way : way : way',\n",
       " 'deliberate : deliber : delib : deliberate',\n",
       " 'set : set : set : set',\n",
       " 'body : bodi : body : body',\n",
       " 'spoke : spoke : spok : spoke',\n",
       " 'plainly : plainli : plain : plainly',\n",
       " 'figure : figur : fig : figure',\n",
       " \"he'd : he'd : he'd : he'd\",\n",
       " 'make : make : mak : make',\n",
       " 'years : year : year : year',\n",
       " 'come : come : com : come',\n",
       " 'sandy : sandi : sandy : sandy',\n",
       " 'hair : hair : hair : hair',\n",
       " 'already : alreadi : already : already',\n",
       " 'beginning : begin : begin : beginning',\n",
       " 'thin : thin : thin : thin',\n",
       " 'recede : reced : rec : recede',\n",
       " 'sides : side : sid : side',\n",
       " 'Abel : abel : abel : Abel',\n",
       " 'looked : look : look : looked',\n",
       " 'quickly : quickli : quick : quickly',\n",
       " 'away : away : away : away',\n",
       " 'Mark : mark : mark : Mark',\n",
       " 'easily : easili : easy : easily',\n",
       " 'looked : look : look : looked',\n",
       " 'years : year : year : year',\n",
       " 'older : older : old : older',\n",
       " 'settled : settl : settl : settled',\n",
       " 'world : world : world : world',\n",
       " 'comfortably : comfort : comfort : comfortably',\n",
       " 'categorized : categor : categ : categorized',\n",
       " 'vacation : vacat : vac : vacation',\n",
       " 'traffic : traffic : traff : traffic',\n",
       " 'becoming : becom : becom : becoming',\n",
       " 'heavier : heavier : heavy : heavier',\n",
       " 'approached : approach : approach : approached',\n",
       " 'sea : sea : sea : sea',\n",
       " '`` : `` : `` : ``',\n",
       " 'mention : mention : ment : mention',\n",
       " 'bringing : bring : bring : bringing',\n",
       " 'Myra : myra : myr : Myra',\n",
       " \"'' : '' : '' : ''\",\n",
       " 'Mark : mark : mark : Mark',\n",
       " 'said : said : said : said',\n",
       " 'maneuvering : maneuv : maneuv : maneuvering',\n",
       " 'car : car : car : car',\n",
       " 'next : next : next : next',\n",
       " 'lane : lane : lan : lane',\n",
       " '`` : `` : `` : ``',\n",
       " 'probably : probabl : prob : probably',\n",
       " 'getting : get : get : getting',\n",
       " 'old : old : old : old',\n",
       " '-- : -- : -- : --',\n",
       " 'crotchety : crotcheti : crotch : crotchety',\n",
       " 'mean : mean : mean : mean',\n",
       " '-- : -- : -- : --',\n",
       " 'figured : figur : fig : figured',\n",
       " 'uh-uh : uh-uh : uh-uh : uh-uh',\n",
       " 'better : better : bet : better',\n",
       " \"They've : they'v : they've : They've\",\n",
       " 'never : never : nev : never',\n",
       " 'met : met : met : met',\n",
       " 'know : know : know : know',\n",
       " 'Myra : myra : myr : Myra',\n",
       " 'budge : budg : budg : budge',\n",
       " 'without : without : without : without',\n",
       " 'express : express : express : express',\n",
       " 'invitation : invit : invit : invitation',\n",
       " 'feel : feel : feel : feel',\n",
       " 'kind : kind : kind : kind',\n",
       " 'bad : bad : bad : bad',\n",
       " \"'' : '' : '' : ''\",\n",
       " 'gave : gave : gav : gave',\n",
       " 'Abel : abel : abel : Abel',\n",
       " 'quick : quick : quick : quick',\n",
       " 'glance : glanc : glant : glance',\n",
       " 'moved : move : mov : moved',\n",
       " 'closer : closer : clos : closer',\n",
       " 'wheel : wheel : wheel : wheel',\n",
       " 'hugging : hug : hug : hugging',\n",
       " 'Abel : abel : abel : Abel',\n",
       " 'caught : caught : caught : caught',\n",
       " 'briefest : briefest : briefest : briefest',\n",
       " 'allusions : allus : allud : allusion',\n",
       " 'guilt : guilt : guilt : guilt',\n",
       " '`` : `` : `` : ``',\n",
       " 'imagine : imagin : imagin : imagine',\n",
       " 'old : old : old : old',\n",
       " 'girl : girl : girl : girl',\n",
       " 'missed : miss : miss : missed',\n",
       " 'us : us : us : u',\n",
       " 'much : much : much : much',\n",
       " \"'' : '' : '' : ''\",\n",
       " 'Mark : mark : mark : Mark',\n",
       " 'added : ad : ad : added',\n",
       " 'eyes : eye : ey : eye',\n",
       " 'road : road : road : road',\n",
       " 'Abel : abel : abel : Abel',\n",
       " 'ignored : ignor : ign : ignored',\n",
       " 'half-expressed : half-express : half-expressed : half-expressed',\n",
       " 'bid : bid : bid : bid',\n",
       " 'confirmation : confirm : confirm : confirmation',\n",
       " 'smiled : smile : smil : smiled',\n",
       " 'barely : bare : bar : barely',\n",
       " 'possible : possibl : poss : possible',\n",
       " 'brother : brother : broth : brother',\n",
       " 'right : right : right : right',\n",
       " 'could : could : could : could',\n",
       " 'tell : tell : tel : tell',\n",
       " 'approaching : approach : approach : approaching',\n",
       " 'sea : sea : sea : sea',\n",
       " 'air : air : air : air',\n",
       " 'took : took : took : took',\n",
       " 'special : special : spec : special',\n",
       " 'strength : strength : strength : strength',\n",
       " \"they'd : they'd : they'd : they'd\",\n",
       " 'left : left : left : left',\n",
       " 'fecund : fecund : fecund : fecund',\n",
       " 'warmth : warmth : warm : warmth',\n",
       " 'farmland : farmland : farmland : farmland',\n",
       " 'behind : behind : behind : behind',\n",
       " 'smell : smell : smel : smell',\n",
       " 'coast : coast : coast : coast',\n",
       " 'like : like : lik : like',\n",
       " 'primeval : primev : primev : primeval',\n",
       " 'memory : memori : mem : memory',\n",
       " 'composed : compos : compos : composed',\n",
       " 'equal : equal : eq : equal',\n",
       " 'parts : part : part : part',\n",
       " 'salt : salt : salt : salt',\n",
       " 'water : water : wat : water',\n",
       " 'clams : clam : clam : clam',\n",
       " 'seaweed : seawe : seawee : seaweed',\n",
       " 'northern : northern : northern : northern',\n",
       " 'air : air : air : air',\n",
       " 'turned : turn : turn : turned',\n",
       " 'flying : fli : fly : flying',\n",
       " 'trees : tree : tre : tree',\n",
       " 'look : look : look : look',\n",
       " 'ahead : ahead : ahead : ahead',\n",
       " 'saw : saw : saw : saw',\n",
       " 'inward : inward : inward : inward',\n",
       " \"boy's : boy' : boy's : boy's\",\n",
       " 'eye : eye : ey : eye',\n",
       " 'great : great : gre : great',\n",
       " 'fieldstone : fieldston : fieldston : fieldstone',\n",
       " 'house : hous : hous : house',\n",
       " 'built : built : built : built',\n",
       " 'one : one : on : one',\n",
       " 'many : mani : many : many',\n",
       " 'acres : acr : acr : acre',\n",
       " 'ancestral : ancestr : ancest : ancestral',\n",
       " 'land : land : land : land',\n",
       " 'bordering : border : bord : bordering',\n",
       " 'west : west : west : west',\n",
       " 'harbor : harbor : harb : harbor',\n",
       " \"Izaak's : izaak' : izaak's : Izaak's\",\n",
       " 'bride-gift : bride-gift : bride-gift : bride-gift',\n",
       " 'cousin-wife : cousin-wif : cousin-wife : cousin-wife',\n",
       " 'last : last : last : last',\n",
       " 'century : centuri : century : century',\n",
       " 'ended : end : end : ended',\n",
       " \"Mark's : mark' : mark's : Mark's\",\n",
       " 'thoughts : thought : thought : thought',\n",
       " 'must : must : must : must',\n",
       " 'keeping : keep : keep : keeping',\n",
       " 'silent : silent : sil : silent',\n",
       " 'pace : pace : pac : pace',\n",
       " 'beside : besid : besid : beside',\n",
       " 'climbing : climb : climb : climbing',\n",
       " 'crags : crag : crag : crag',\n",
       " 'dirty : dirti : dirty : dirty',\n",
       " 'white : white : whit : white',\n",
       " 'sneakers : sneaker : sneak : sneaker',\n",
       " 'clambering : clamber : clamb : clambering',\n",
       " 'top : top : top : top',\n",
       " 'headland : headland : headland : headland',\n",
       " 'coming : come : com : coming',\n",
       " 'upon : upon : upon : upon',\n",
       " 'sudden : sudden : sud : sudden',\n",
       " 'glinting : glint : glint : glinting',\n",
       " 'water : water : wat : water',\n",
       " 'instant : instant : inst : instant',\n",
       " '`` : `` : `` : ``',\n",
       " 'Remember : rememb : rememb : Remember',\n",
       " 'Starbird : starbird : starbird : Starbird',\n",
       " \"'' : '' : '' : ''\",\n",
       " 'Mark : mark : mark : Mark',\n",
       " 'asked : ask : ask : asked',\n",
       " 'Abel : abel : abel : Abel',\n",
       " 'lifted : lift : lift : lifted',\n",
       " 'eyes : eye : ey : eye',\n",
       " 'double : doubl : doubl : double',\n",
       " 'lines : line : lin : line',\n",
       " 'middle : middl : middl : middle',\n",
       " 'road : road : road : road',\n",
       " 'twin : twin : twin : twin',\n",
       " 'white : white : whit : white',\n",
       " 'ribbons : ribbon : ribbon : ribbon',\n",
       " 'car : car : car : car',\n",
       " 'swallowed : swallow : swallow : swallowed',\n",
       " 'rapidly : rapidli : rapid : rapidly',\n",
       " 'ascended : ascend : ascend : ascended',\n",
       " 'crest : crest : crest : crest',\n",
       " 'hill : hill : hil : hill',\n",
       " 'came : came : cam : came',\n",
       " '`` : `` : `` : ``',\n",
       " 'Starbird : starbird : starbird : Starbird',\n",
       " \"'' : '' : '' : ''\",\n",
       " 'Abel : abel : abel : Abel',\n",
       " 'said : said : said : said',\n",
       " 'day : day : day : day',\n",
       " 'Uncle : uncl : unc : Uncle',\n",
       " 'Izaak : izaak : izaak : Izaak',\n",
       " 'unexpected : unexpect : unexpect : unexpected',\n",
       " 'grandiose : grandios : grandios : grandiose',\n",
       " 'gesture : gestur : gest : gesture',\n",
       " 'handed : hand : hand : handed',\n",
       " 'pretty : pretti : pretty : pretty',\n",
       " 'sloop : sloop : sloop : sloop',\n",
       " 'Abel : abel : abel : Abel',\n",
       " 'keeps : keep : keep : keep',\n",
       " 'condition : condit : condit : condition',\n",
       " 'never : never : nev : never',\n",
       " 'fail : fail : fail : fail',\n",
       " 'let : let : let : let',\n",
       " 'brother : brother : broth : brother',\n",
       " 'accompany : accompani : accompany : accompany',\n",
       " 'whenever : whenev : whenev : whenever',\n",
       " 'younger : younger : young : younger',\n",
       " 'boy : boy : boy : boy',\n",
       " 'wished : wish : wish : wished',\n",
       " 'two : two : two : two',\n",
       " 'developed : develop : develop : developed',\n",
       " 'remarkable : remark : remark : remarkable',\n",
       " 'sailing : sail : sail : sailing',\n",
       " 'team : team : team : team',\n",
       " 'happening : happen : hap : happening',\n",
       " 'time : time : tim : time',\n",
       " 'lives : live : liv : life',\n",
       " 'youth : youth : you : youth',\n",
       " 'brotherhood : brotherhood : broth : brotherhood',\n",
       " 'knitted : knit : knit : knitted',\n",
       " 'together : togeth : togeth : together',\n",
       " 'time : time : tim : time',\n",
       " 'circumstance : circumst : circumst : circumstance',\n",
       " 'could : could : could : could',\n",
       " 'seemed : seem : seem : seemed',\n",
       " 'single : singl : singl : single',\n",
       " 'mind : mind : mind : mind',\n",
       " 'body : bodi : body : body',\n",
       " 'mutuality : mutual : mut : mutuality',\n",
       " ...]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lemmatization compared to Stemming\n",
    "from nltk.stem import PorterStemmer\n",
    "porter = PorterStemmer()\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wordNet = WordNetLemmatizer()\n",
    "\n",
    "StemmersCompared = [word+' : '+porter.stem(word)+' : '+lancaster.stem(word)+' : '+wordNet.lemmatize(word) for word in wordList]\n",
    "StemmersCompared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "60Byit-CxWEf",
    "Oa7p8sucxWEp"
   ],
   "name": "NLP basics.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
